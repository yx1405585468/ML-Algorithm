{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ç†è®ºçŸ¥è¯†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ID3ï¼ˆIterative Dichotomiser 3ï¼‰æ˜¯ä¸€ç§å¸¸ç”¨çš„å†³ç­–æ ‘ç®—æ³•ï¼Œä¸»è¦ç”¨äº**åˆ†ç±»**ä»»åŠ¡ã€‚å®ƒé€šè¿‡æ„å»ºæ ‘å½¢æ¨¡å‹æ¥å¸®åŠ©å†³ç­–ã€‚\n",
    "\n",
    "2. **ç‰¹å¾é€‰æ‹©**ï¼š ID3 é€šè¿‡è®¡ç®—**ä¿¡æ¯å¢ç›Š**æ¥é€‰æ‹©æœ€ä½³ç‰¹å¾ã€‚**ä¿¡æ¯å¢ç›Š**æ˜¯æŒ‡ä½¿ç”¨æŸä¸€ç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œæ‰€å¸¦æ¥çš„**ä¸ç¡®å®šæ€§å‡å°‘ç¨‹åº¦**ã€‚ID3 é¦–å…ˆè®¡ç®—æ•´ä¸ªæ•°æ®é›†çš„ç†µï¼Œç„¶åè®¡ç®—åœ¨æ¯ä¸ªç‰¹å¾ä¸‹çš„æ¡ä»¶ç†µï¼Œä¿¡æ¯å¢ç›Šåˆ™æ˜¯äºŒè€…çš„å·®å€¼ã€‚\n",
    "\n",
    "3. **ç†µ**ï¼š **ç†µ**æ˜¯è¡¡é‡ä¿¡æ¯ä¸ç¡®å®šæ€§çš„ä¸€ä¸ªæŒ‡æ ‡ã€‚**ç†µè¶Šé«˜ï¼Œä¸ç¡®å®šæ€§è¶Šå¤§ï¼›ç†µè¶Šä½ï¼Œä¸ç¡®å®šæ€§è¶Šå°**ã€‚ID3 é€šè¿‡è®¡ç®—æ•°æ®é›†ä¸­æ¯ä¸ªç±»åˆ«çš„åˆ†å¸ƒæ¥ç¡®å®šç†µã€‚\n",
    "\n",
    "4. **é€’å½’æ„å»º**ï¼š ID3 é‡‡ç”¨é€’å½’æ–¹æ³•æ¥æ„å»ºæ ‘ã€‚ä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œé€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ä½œä¸ºå½“å‰èŠ‚ç‚¹ï¼Œç„¶åæ ¹æ®è¯¥ç‰¹å¾çš„ä¸åŒå–å€¼åˆ†å‰²æ•°æ®é›†ï¼Œç»§ç»­ä¸ºæ¯ä¸ªå­é›†æ„å»ºå­æ ‘ï¼Œç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ï¼ˆå¦‚æ‰€æœ‰æ ·æœ¬å±äºåŒä¸€ç±»åˆ«æˆ–æ²¡æœ‰ç‰¹å¾å¯ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.æ•°æ®å‡†å¤‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 å¯¼å…¥æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>èŠ±è¼é•¿åº¦</th>\n",
       "      <th>èŠ±è¼å®½åº¦</th>\n",
       "      <th>èŠ±ç“£é•¿åº¦</th>\n",
       "      <th>èŠ±ç“£å®½åº¦</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     èŠ±è¼é•¿åº¦  èŠ±è¼å®½åº¦  èŠ±ç“£é•¿åº¦  èŠ±ç“£å®½åº¦\n",
       "0     5.1   3.5   1.4   0.2\n",
       "1     4.9   3.0   1.4   0.2\n",
       "2     4.7   3.2   1.3   0.2\n",
       "3     4.6   3.1   1.5   0.2\n",
       "4     5.0   3.6   1.4   0.2\n",
       "..    ...   ...   ...   ...\n",
       "145   6.7   3.0   5.2   2.3\n",
       "146   6.3   2.5   5.0   1.9\n",
       "147   6.5   3.0   5.2   2.0\n",
       "148   6.2   3.4   5.4   2.3\n",
       "149   5.9   3.0   5.1   1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¯¼å…¥æ¨¡å—\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# å¤„ç†æ•°æ®é›†\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "y = pd.DataFrame(data=iris.target, columns=[\"label\"])\n",
    "\n",
    "\n",
    "# ç‰¹å¾é‡å‘½å\n",
    "map_ = {\n",
    "    \"sepal length (cm)\": \"èŠ±è¼é•¿åº¦\",\n",
    "    \"sepal width (cm)\": \"èŠ±è¼å®½åº¦\",\n",
    "    \"petal length (cm)\": \"èŠ±ç“£é•¿åº¦\",\n",
    "    \"petal width (cm)\": \"èŠ±ç“£å®½åº¦\",\n",
    "}\n",
    "X = X.rename(columns=map_)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ID3æ ‘è¦æ±‚ç‰¹å¾æ˜¯**ç¦»æ•£**çš„ï¼Œå› æ­¤éœ€è¦å¯¹Irisæ•°æ®é›†è¿›è¡Œ**åˆ†ç®±**æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [1, 3, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 3, 0, 0],\n",
       "       [1, 3, 0, 0],\n",
       "       [1, 3, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [1, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [1, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 2, 0, 0],\n",
       "       [0, 3, 0, 0],\n",
       "       [1, 3, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 2, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [2, 1, 2, 2],\n",
       "       [2, 1, 2, 2],\n",
       "       [2, 1, 2, 2],\n",
       "       [1, 0, 2, 1],\n",
       "       [2, 1, 2, 2],\n",
       "       [1, 1, 2, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [0, 0, 1, 1],\n",
       "       [2, 1, 2, 1],\n",
       "       [0, 1, 1, 2],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 2, 2],\n",
       "       [1, 0, 2, 1],\n",
       "       [1, 1, 2, 2],\n",
       "       [1, 1, 1, 1],\n",
       "       [2, 1, 2, 2],\n",
       "       [1, 1, 2, 2],\n",
       "       [1, 1, 2, 1],\n",
       "       [2, 0, 2, 2],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 2, 2],\n",
       "       [1, 1, 2, 1],\n",
       "       [2, 0, 2, 2],\n",
       "       [1, 1, 2, 1],\n",
       "       [2, 1, 2, 1],\n",
       "       [2, 1, 2, 2],\n",
       "       [2, 1, 2, 2],\n",
       "       [2, 1, 2, 2],\n",
       "       [1, 1, 2, 2],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 2, 2],\n",
       "       [1, 1, 2, 2],\n",
       "       [1, 2, 2, 2],\n",
       "       [2, 1, 2, 2],\n",
       "       [2, 0, 2, 1],\n",
       "       [1, 1, 2, 1],\n",
       "       [1, 0, 2, 1],\n",
       "       [1, 0, 2, 1],\n",
       "       [1, 1, 2, 2],\n",
       "       [1, 0, 2, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 2, 1],\n",
       "       [1, 1, 2, 1],\n",
       "       [1, 1, 2, 1],\n",
       "       [2, 1, 2, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 2, 1],\n",
       "       [2, 2, 3, 3],\n",
       "       [1, 1, 2, 2],\n",
       "       [3, 1, 3, 3],\n",
       "       [2, 1, 3, 2],\n",
       "       [2, 1, 3, 3],\n",
       "       [3, 1, 3, 3],\n",
       "       [0, 0, 2, 2],\n",
       "       [3, 1, 3, 2],\n",
       "       [2, 0, 3, 2],\n",
       "       [3, 2, 3, 3],\n",
       "       [2, 1, 2, 3],\n",
       "       [2, 1, 2, 2],\n",
       "       [2, 1, 3, 3],\n",
       "       [1, 0, 2, 3],\n",
       "       [1, 1, 2, 3],\n",
       "       [2, 1, 2, 3],\n",
       "       [2, 1, 3, 2],\n",
       "       [3, 2, 3, 3],\n",
       "       [3, 0, 3, 3],\n",
       "       [1, 0, 2, 2],\n",
       "       [2, 1, 3, 3],\n",
       "       [1, 1, 2, 3],\n",
       "       [3, 1, 3, 3],\n",
       "       [2, 1, 2, 2],\n",
       "       [2, 2, 3, 3],\n",
       "       [3, 1, 3, 2],\n",
       "       [2, 1, 2, 2],\n",
       "       [1, 1, 2, 2],\n",
       "       [2, 1, 3, 3],\n",
       "       [3, 1, 3, 2],\n",
       "       [3, 1, 3, 2],\n",
       "       [3, 2, 3, 3],\n",
       "       [2, 1, 3, 3],\n",
       "       [2, 1, 2, 2],\n",
       "       [1, 0, 3, 2],\n",
       "       [3, 1, 3, 3],\n",
       "       [2, 2, 3, 3],\n",
       "       [2, 1, 3, 2],\n",
       "       [1, 1, 2, 2],\n",
       "       [2, 1, 2, 3],\n",
       "       [2, 1, 3, 3],\n",
       "       [2, 1, 2, 3],\n",
       "       [1, 1, 2, 2],\n",
       "       [2, 1, 3, 3],\n",
       "       [2, 2, 3, 3],\n",
       "       [2, 1, 2, 3],\n",
       "       [2, 0, 2, 2],\n",
       "       [2, 1, 2, 3],\n",
       "       [2, 2, 2, 3],\n",
       "       [1, 1, 2, 2]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¯¹æ¯ä¸€åˆ—ç‰¹å¾è¿›è¡Œåˆ†ç®±\n",
    "X_new = pd.DataFrame()\n",
    "for c in X.columns:\n",
    "    binned_data = pd.cut(X[c], bins=4, labels=[0, 1, 2, 3])\n",
    "    X_new = pd.concat([X_new, binned_data], axis=1)\n",
    "\n",
    "# ArrayåŒ–ï¼Œæ–¹ä¾¿è®¡ç®—\n",
    "X_new = np.array(X_new)\n",
    "y = np.array(y)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. æ„å»ºID3æ ‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 ç†µä¸ä¿¡æ¯å¢ç›Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ä¿¡æ¯ç†µçš„è®¡ç®—ï¼šåœ¨åˆ†ç±»æ•°æ®é›†ä¸­ï¼Œä¿¡æ¯ç†µç”¨æ¥è¡¡é‡ æ•°æ®é›†ä¸­**æ ‡ç­¾** çš„ **çº¯åº¦æˆ–ä¸ç¡®å®šæ€§**ã€‚å…·ä½“æ¥è¯´ï¼Œä¿¡æ¯ç†µè¶Šé«˜ï¼Œè¡¨ç¤ºæ•°æ®é›†ä¸­æ ‡ç­¾çš„ç±»åˆ«åˆ†å¸ƒè¶Šåˆ†æ•£ï¼Œè¶Šä¸çº¯ï¼›ä¿¡æ¯ç†µè¶Šä½ï¼Œè¡¨ç¤ºæ ‡ç­¾çš„ç±»åˆ«è¶Šé›†ä¸­ï¼Œæ•°æ®é›†è¶Šçº¯ã€‚é‚£ä¹ˆï¼Œå¦‚ä½•è®¡ç®—ä¿¡æ¯ç†µï¼Œä»¥åŠä¿¡æ¯å¢ç›Šå‘¢ï¼Ÿ\n",
    "\n",
    "2. ![Example Image](img/ä¿¡æ¯ç†µ1.jpg)\n",
    "\n",
    "3. **å°†æ•°æ®é›†æ ¹æ®æŸä¸ªç‰¹å¾åˆ†æˆè‹¥å¹²ä¸ªå­é›†ã€‚å‡è®¾ç‰¹å¾ ğ´ æœ‰ ğ‘‰ ä¸ªå¯èƒ½å–å€¼ã€‚æ¯ä¸ªå–å€¼å°†æ•°æ®é›†åˆ’åˆ†æˆä¸€ä¸ªå­é›†ã€‚**\n",
    "\n",
    "5. ![Example Image](img/å­é›†ä¿¡æ¯ç†µ1.jpg)\n",
    "\n",
    "6. æœ€åï¼ŒåŠ æƒå­é›†ä¿¡æ¯ç†µï¼Œè®¡ç®—æ¡ä»¶ç†µä¸ä¿¡æ¯å¢ç›Šã€‚\n",
    "\n",
    "7. ![Example Image](img/æ¡ä»¶ç†µä¸ä¿¡æ¯å¢ç›Š1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. éœ€è¦æ³¨æ„ï¼š**å­é›†ä¿¡æ¯ç†µå…¬å¼** = **åŸæ•°æ®é›†ä¿¡æ¯ç†µå…¬å¼**\n",
    "\n",
    "2. æ¡ä»¶ç†µ = å­é›†çš„ä¿¡æ¯ç†µ * å­é›†æ¯”ä¾‹ï¼Œå¦‚å¯¹ç‰¹å¾Aæœ‰4ä¸ªå­é›†ï¼Œæ¯ä¸ªå­é›†çš„ä¿¡æ¯ç†µä¸º[0.2, 0.3, 0.4, 0.1]ï¼Œæ¯ä¸ªå­é›†çš„æ¯”ä¾‹[0.1, 0.5, 0.3, 0.1]\n",
    "\n",
    "3. åˆ™ç‰¹å¾Açš„æ¡ä»¶ç†µï¼šå³ä»¥ç‰¹å¾Aåˆ’åˆ†æ—¶ï¼Œçš„å­é›†çš„ç†µçš„åŠ æƒå’Œ = [0.2*0.1 + 0.3*0.5 + 0.4*0.3 + 0.1*0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.584962500721156\n",
      "1.584962500721156\n"
     ]
    }
   ],
   "source": [
    "# è®¡ç®—ä¿¡æ¯ç†µ\n",
    "\n",
    "# æˆ‘å†™çš„ï¼š\n",
    "def get_entropy_me(y_):\n",
    "    entropy = -np.sum(\n",
    "        [\n",
    "            (i / y_.shape[0]) * np.log2(i / y_.shape[0])\n",
    "            for i in np.unique(y_, return_counts=True)[1]\n",
    "        ]\n",
    "    )\n",
    "    return entropy\n",
    "\n",
    "\n",
    "# gptå†™çš„\n",
    "def get_entropy_gpt(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "\n",
    "# æ‰“å°ç†µå€¼\n",
    "print(get_entropy_gpt(y))\n",
    "print(get_entropy_me(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6491037267564883\n",
      "0.6491037267564883\n"
     ]
    }
   ],
   "source": [
    "# è®¡ç®—ä¿¡æ¯å¢ç›Š\n",
    "\n",
    "# æˆ‘å†™çš„\n",
    "def get_information_gain_me(y_, x_):\n",
    "\n",
    "    # æ ¹æ®ç»™å®šçš„è¿™ä¸€åˆ—ç‰¹å¾ä¸åŒå€¼, æ‰¾åˆ°å¯¹åº”çš„å­é›†index\n",
    "    indexs = [np.where(x_ == i) for i in np.unique(x_)] \n",
    "\n",
    "    # æ ¹æ®å­é›†indexæ‰¾åˆ°å­é›†y, æ±‚å­é›†yçš„çš„ä¿¡æ¯ç†µå¹¶åŠ æƒæ±‚å’Œ\n",
    "    x_entropy = np.sum([get_entropy_me(y[i]) * (len(y[i]) / len(y)) for i in indexs]) \n",
    "\n",
    "    # è¿”å›ä¿¡æ¯å¢ç›Š\n",
    "    return get_entropy_me(y_) - x_entropy\n",
    "\n",
    "\n",
    "# gptå†™çš„\n",
    "def get_information_gain_gpt(y_, x_):\n",
    "\n",
    "    # è®¡ç®—æ•´ä½“ç†µ\n",
    "    total_entropy = get_entropy_gpt(y_)\n",
    "\n",
    "    # è®¡ç®—ç‰¹å¾ x çš„æ¯ä¸ªå”¯ä¸€å€¼çš„ç†µ\n",
    "    unique_values = np.unique(x_)\n",
    "\n",
    "    weighted_entropy = 0\n",
    "    for value in unique_values:\n",
    "\n",
    "        # è·å–ç‰¹å¾ x ç­‰äºå½“å‰å€¼çš„æ ·æœ¬\n",
    "        subset = y[x_ == value]\n",
    "\n",
    "        # è®¡ç®—è¯¥å­é›†çš„ç†µ\n",
    "        subset_entropy = get_entropy_gpt(subset)\n",
    "\n",
    "        # è®¡ç®—è¯¥å­é›†çš„æƒé‡\n",
    "        weight = len(subset) / len(y_)\n",
    "\n",
    "        # åŠ æƒç†µ\n",
    "        weighted_entropy += weight * subset_entropy\n",
    "\n",
    "    # è®¡ç®—ä¿¡æ¯å¢ç›Š\n",
    "    gain = total_entropy - weighted_entropy\n",
    "    return gain\n",
    "\n",
    "print(get_information_gain_me(y, X_new[:, 0]))\n",
    "print(get_information_gain_gpt(y, X_new[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ„å»ºå†³ç­–æ ‘\n",
    "def get_best_feature(y_, x_):\n",
    "    score = []\n",
    "    for i in range(x_.shape[1]):\n",
    "        gain_i = get_information_gain_me(y_, x_[:, i])\n",
    "        score.append(gain_i)\n",
    "\n",
    "    # æœ€å¤§ä¿¡æ¯å¢ç›Šçš„ç‰¹å¾\n",
    "    return np.argmax(score)\n",
    "\n",
    "\n",
    "get_best_feature(y, X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearnä¸­æ¨¡å‹è®¡ç®—\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_new, y)\n",
    "model.fit(x_train, y_train)\n",
    "y_pre = model.predict(x_test)\n",
    "accuracy_score(y_test, y_pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
